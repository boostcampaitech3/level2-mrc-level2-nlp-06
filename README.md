# ğŸ’¡ Machine Reading Comprehension (MRC) Project ğŸ’¡


### ğŸ‘© í”„ë¡œì íŠ¸ íŒ€ êµ¬ì„± ë° ì—­í•  ğŸ‘¨

|ê¹€ì„ ì¬|ì°¨ê²½ë¯¼|ì´ë„í›ˆ|ê°•ì§„í¬|ê¹€íƒœí›ˆ|
|--|--|--|--|--|
|Optimization, Model, Elastic Search:|Augementation, EDA, Model, Dense Retriever, Preprocessing|Optimization, EDA, BM25, Ensemble, Dense Retival|Optimization, Model, EDA, Sparse Retrival|EDA, Management, Question Generation| 
<br/>


### âœ… í”„ë¡œì íŠ¸ ê°œìš”

![image](https://user-images.githubusercontent.com/86389775/169706163-62a41196-9b2b-470f-89c5-caff728decc4.png)
<br/>
- ì§€ë¬¸ì´ ë”°ë¡œ ì£¼ì–´ì§€ì§€ ì•Šê³  ì‚¬ì „ì— êµ¬ì¶•ë˜ì–´ ìˆëŠ” Knowledge resourceì—ì„œ ì§ˆë¬¸ì— ëŒ€í•´ ëŒ€ë‹µí•  ìˆ˜ ìˆëŠ” ë¬¸ì„œë¥¼ ì°¾ì€ í›„, í•´ë‹¹ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì„ ì°¾ëŠ” ë¬¸ì œ
- Query ë¬¸ì¥ ì…ë ¥ìœ¼ë¡œ 2ë‹¨ê³„ Task ìˆ˜í–‰
    1. __Documnet Retriever__ - ë¬¸ì„œ ì‚¬ì „ì—ì„œ Queryì— ëŒ€ë‹µ í•  ìˆ˜ ìˆëŠ” ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ëª¨ë¸
    2. __Document Reader__ - Retrieverë¡œ ë°˜í™˜ëœ ë¬¸ì„œì—ì„œ Queryì™€ ê°€ì¥ ê´€ë ¨ ê¹Šì€ Phase ì°¾ëŠ” ëª¨ë¸
<br/>    


### âœ… í”„ë¡œì íŠ¸ íƒ€ì„ë¼ì¸

|ì£¼ì°¨|ìˆ˜í–‰ í•­ëª©|
|----|----|
|1ì£¼ì°¨|ììœ¨ì ì¸ ì‹¤í—˜ ì•„ì´ë””ì–´ ê³µìœ  ë° ì‹¤í—˜ ê³„íšê³¼ ìˆ˜í–‰, ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ ë° ë°ì´í„° ì¦ê°•, ì‹¤í—˜ í™˜ê²½ ì„¸íŒ…|
|2ì£¼ì°¨|ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„ íƒ ë° ê²°ê³¼ ê³µìœ , ëª¨ë¸ ìµœì í™”, Retriever, Preprocessing, Elastic search ì‹¤í—˜|
|3ì£¼ì°¨|Retriever, Preprocessing, Elastic search ì‹¤í—˜, ëª¨ë¸ ìµœì í™” ë° ì•™ìƒë¸” ìˆ˜í–‰|
<br/>


### âœ… í”„ë¡œì íŠ¸ ìˆ˜í–‰ ê²°ê³¼

ğŸ“Œ __Data Augementation__

1. ì£¼ì–´ì§„ Question, Context ë°ì´í„° í¬ê¸°ê°€ ë‹¤ë¥¸ pre-trained ëª¨ë¸ì— ì‚¬ìš©ëœ ë°ì´í„° ì…‹ì— ë¹„í•´ ê·œëª¨ê°€ ì‘ë‹¤ íŒë‹¨
2. ê¸°ì¡´ì˜ ë°ì´í„°ì…‹ + KorQuAD ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ ì§„í–‰ì‹œì¼°ì§€ë§Œ íš¨ê³¼ ë¯¸ë¯¸
3. Back-translationì„ í†µí•´ ë°ì´í„° ì¦ê°• ì‹œë„í–ˆìœ¼ë‚˜ ì„±ëŠ¥ ì €í•˜ ê¸°ë¡<br/>

ğŸ“Œ __Preprocessing__

1. Wikipedia ë°ì´í„° ì…‹ì— íŠ¹ìˆ˜ ë¬¸ì í¬í•¨ => Retrieval ì„±ëŠ¥ ì €í•˜ì— ì˜í–¥ ì¤„ ê²ƒì´ë¼ íŒë‹¨
2. â€˜\nâ€™, â€˜#â€™, í•œì ë“± ë¬¸ì ì œê±°
3. ë™ì¼ ì¡°ê±´ ëŒ€ë¹„ 1 ~ 2% ì„±ëŠ¥ í–¥ìƒ ê¸°ë¡<br/>

ğŸ“Œ __BM25__

![image](https://user-images.githubusercontent.com/86389775/169706099-9f6e5f0d-c2ec-4ff4-9709-cb4cef7728df.png)
<br/>  
1. ì£¼ì–´ì§„ ì¿¼ë¦¬ì— ëŒ€í•´ ë¬¸ì„œì˜ ì—°ê´€ì„±ì„ í‰ê°€í•˜ëŠ” ë­í‚¹ í•¨ìˆ˜
2. TF-IDFì˜ ê°œë…ì„ ë°”íƒ•ìœ¼ë¡œ, ë¬¸ì„œì˜ ê¸¸ì´ê¹Œì§€ ê³ ë ¤í•˜ì—¬ scoring í•˜ë©°, TF ê°’ì— í•œê³„ë¥¼ ì§€ì •í•´ë‘ì–´ ì¼ì •í•œ ë²”ìœ„ë¥¼ ìœ ì§€
3. rank_bm25ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„, ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ EM score 15ì  ê°€ëŸ‰ ì„±ëŠ¥ í–¥ìƒ ê¸°ë¡<br/>

ğŸ“Œ __Dense Retrieval__

1. Passageì™€ Questionì„ ê°ê°ì˜ pretrained modelì„ ë§Œë“¤ì–´ì„œ hidden representation ë²¡í„°ë“¤ì˜ ë‚´ì ì„ í†µí•´ ë‹µì„ ì–»ì„ ìˆ˜ ìˆëŠ” passageì™€ questionì˜ ë‚´ì  ê°’ì„ ë†’ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµ ì‹œí‚¤ëŠ” ë°©ë²•
2. [ë…¼ë¬¸](https://arxiv.org/abs/2004.04906)ì—ì„œ ì œì‹œí•œ in-batch negative sampling ê¸°ë²•ì„ í†µí•´ Dense Retrievalì„ êµ¬í˜„ ì‹œë„  => Dataset sizeì˜ í•œê³„ì™€ GPU resourceì˜ ì œí•œìœ¼ë¡œ ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ batch sizeë¡œëŠ” ì¬í˜„ ì‹¤íŒ¨

<br/>



## ì½”ë“œ ì„¤ëª…

### âœ… ìš”êµ¬ ì‚¬í•­

```
# data (51.2 MB)
tar -xzf data.tar.gz

# í•„ìš”í•œ íŒŒì´ì¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜. 
bash ./install/install_requirements.sh
```

### âœ… ì €ì¥ì†Œ êµ¬ì¡°

```bash
./assets/                # readme ì— í•„ìš”í•œ ì´ë¯¸ì§€ ì €ì¥
./install/               # ìš”êµ¬ì‚¬í•­ ì„¤ì¹˜ íŒŒì¼ 
./data/                  # ì „ì²´ ë°ì´í„°. ì•„ë˜ ìƒì„¸ ì„¤ëª…
retrieval.py             # sparse retreiver ëª¨ë“ˆ ì œê³µ 
arguments.py             # ì‹¤í–‰ë˜ëŠ” ëª¨ë“  argumentê°€ dataclass ì˜ í˜•íƒœë¡œ ì €ì¥ë˜ì–´ìˆìŒ
trainer_qa.py            # MRC ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ trainer ì œê³µ.
utils_qa.py              # ê¸°íƒ€ ìœ í‹¸ í•¨ìˆ˜ ì œê³µ 

train.py                 # MRC, Retrieval ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ 
inference.py		     # ODQA ëª¨ë¸ í‰ê°€ ë˜ëŠ” ì œì¶œ íŒŒì¼ (predictions.json) ìƒì„±
```

### âœ… ë°ì´í„° ì†Œê°œ

ì•„ë˜ëŠ” ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ì˜ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

![ë°ì´í„° ë¶„í¬](./assets/dataset.png)

ë°ì´í„°ì…‹ì€ í¸ì˜ì„±ì„ ìœ„í•´ Huggingface ì—ì„œ ì œê³µí•˜ëŠ” datasetsë¥¼ ì´ìš©í•˜ì—¬ pyarrow í˜•ì‹ì˜ ë°ì´í„°ë¡œ ì €ì¥ë˜ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ë°ì´í„°ì…‹ì˜ êµ¬ì„±ì…ë‹ˆë‹¤.

```bash
./data/                        # ì „ì²´ ë°ì´í„°
    ./train_dataset/           # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹. train ê³¼ validation ìœ¼ë¡œ êµ¬ì„± 
    ./test_dataset/            # ì œì¶œì— ì‚¬ìš©ë  ë°ì´í„°ì…‹. validation ìœ¼ë¡œ êµ¬ì„± 
    ./wikipedia_documents.json # ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ ì§‘í•©. retrievalì„ ìœ„í•´ ì“°ì´ëŠ” corpus.
```

dataì— ëŒ€í•œ argument ëŠ” `arguments.py` ì˜ `DataTrainingArguments` ì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤. 


### âœ… Train

ë§Œì•½ arguments ì— ëŒ€í•œ ì„¸íŒ…ì„ ì§ì ‘í•˜ê³  ì‹¶ë‹¤ë©´ `arguments.py` ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”. 

roberta ëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° tokenizer ì‚¬ìš©ì‹œ ì•„ë˜ í•¨ìˆ˜ì˜ ì˜µì…˜ì„ ìˆ˜ì •í•´ì•¼í•©ë‹ˆë‹¤.
ë² ì´ìŠ¤ë¼ì¸ì€ klue/bert-baseë¡œ ì§„í–‰ë˜ë‹ˆ ì´ ë¶€ë¶„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©í•´ì£¼ì„¸ìš” ! 
tokenizerëŠ” train, validation (train.py), test(inference.py) ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ í˜¸ì¶œë˜ì–´ ì‚¬ìš©ë©ë‹ˆë‹¤.
(tokenizerì˜ return_token_type_ids=Falseë¡œ ì„¤ì •í•´ì£¼ì–´ì•¼ í•¨)

```python
# train.py
def prepare_train_features(examples):
        # truncationê³¼ padding(lengthê°€ ì§§ì„ë•Œë§Œ)ì„ í†µí•´ toknizationì„ ì§„í–‰í•˜ë©°, strideë¥¼ ì´ìš©í•˜ì—¬ overflowë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        # ê° exampleë“¤ì€ ì´ì „ì˜ contextì™€ ì¡°ê¸ˆì”© ê²¹ì¹˜ê²Œë©ë‹ˆë‹¤.
        tokenized_examples = tokenizer(
            examples[question_column_name if pad_on_right else context_column_name],
            examples[context_column_name if pad_on_right else question_column_name],
            truncation="only_second" if pad_on_right else "only_first",
            max_length=max_seq_length,
            stride=data_args.doc_stride,
            return_overflowing_tokens=True,
            return_offsets_mapping=True,
            # return_token_type_ids=False, # robertaëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° False, bertë¥¼ ì‚¬ìš©í•  ê²½ìš° Trueë¡œ í‘œê¸°í•´ì•¼í•©ë‹ˆë‹¤.
            padding="max_length" if data_args.pad_to_max_length else False,
        )
```

```bash
# í•™ìŠµ ì˜ˆì‹œ (train_dataset ì‚¬ìš©)
python train.py --output_dir ./models/train_dataset --num_train_epochs 10 --do_train
```

```bash
# Retriever í›ˆë ¨(?)
python train.py --train_retrieval
```

### âœ… Eval

MRC ëª¨ë¸ì˜ í‰ê°€ëŠ”(`--do_eval`) ë”°ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.  ìœ„ í•™ìŠµ ì˜ˆì‹œì— ë‹¨ìˆœíˆ `--do_eval` ì„ ì¶”ê°€ë¡œ ì…ë ¥í•´ì„œ í›ˆë ¨ ë° í‰ê°€ë¥¼ ë™ì‹œì— ì§„í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

```bash
# mrc ëª¨ë¸ í‰ê°€ (train_dataset ì‚¬ìš©)
python train.py --output_dir ./outputs/train_dataset --model_name_or_path ./models/train_dataset/ --do_eval 
```

### âœ… Inference

retrieval ê³¼ mrc ëª¨ë¸ì˜ í•™ìŠµì´ ì™„ë£Œë˜ë©´ `inference.py` ë¥¼ ì´ìš©í•´ odqa ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* í•™ìŠµí•œ ëª¨ë¸ì˜  test_datasetì— ëŒ€í•œ ê²°ê³¼ë¥¼ ì œì¶œí•˜ê¸° ìœ„í•´ì„  ì¶”ë¡ (`--do_predict`)ë§Œ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤. 

* í•™ìŠµí•œ ëª¨ë¸ì´ train_dataset ëŒ€í•´ì„œ ODQA ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë‚˜ì˜¤ëŠ”ì§€ ì•Œê³  ì‹¶ë‹¤ë©´ í‰ê°€(`--do_eval`)ë¥¼ ì§„í–‰í•˜ë©´ ë©ë‹ˆë‹¤.

* inference ê²°ê³¼ë¬¼ json íŒŒì¼ì— prefixë¥¼ ë¶™ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤! (`--name`)ì— ì›í•˜ëŠ” ëª…ì¹­ì„ ì ìœ¼ì‹œë©´ predictions_{name}.json í˜•íƒœë¡œ ì €ì¥ë©ë‹ˆë‹¤. ì¶”í›„ ensembleì„ ìœ„í•´ ì˜ ë³´ê´€í•´ì£¼ì„¸ìš”!

```bash
# ODQA ì‹¤í–‰ (test_dataset ì‚¬ìš©)
# wandb ê°€ ë¡œê·¸ì¸ ë˜ì–´ìˆë‹¤ë©´ ìë™ìœ¼ë¡œ ê²°ê³¼ê°€ wandb ì— ì €ì¥ë©ë‹ˆë‹¤. ì•„ë‹ˆë©´ ë‹¨ìˆœíˆ ì¶œë ¥ë©ë‹ˆë‹¤
python inference.py --output_dir ./outputs/test_dataset/ --dataset_name ../data/test_dataset/ --model_name_or_path ./models/train_dataset/ --do_predict --overwrite_output_dir --name new_case
```

```bash
# í‰ê°€(--do_eval)ì„ ì§„í–‰í•˜ê³  ì‹¶ì„ ë•ŒëŠ” train datasetìœ¼ë¡œ...
python inference.py --output_dir ./outputs/test_dataset/ --dataset_name ../data/train_dataset --model_name_or_path ./models/train_dataset --do_eval --overwrite_output_dir --name new_case
`train_datasetì„ ì‚¬ìš©í•¨!!`
```

### âœ… How to submit

`inference.py` íŒŒì¼ì„ ìœ„ ì˜ˆì‹œì²˜ëŸ¼ `--do_predict` ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ `--output_dir` ìœ„ì¹˜ì— `predictions.json` ì´ë¼ëŠ” íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ì„ ì œì¶œí•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.

### â˜‘ï¸ Things to know

1. `train.py` ì—ì„œ sparse embedding ì„ í›ˆë ¨í•˜ê³  ì €ì¥í•˜ëŠ” ê³¼ì •ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ì§€ ì•Šì•„ ë”°ë¡œ argument ì˜ default ê°€ Trueë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹¤í–‰ í›„ sparse_embedding.bin ê³¼ tfidfv.bin ì´ ì €ì¥ì´ ë©ë‹ˆë‹¤. **ë§Œì•½ sparse retrieval ê´€ë ¨ ì½”ë“œë¥¼ ìˆ˜ì •í•œë‹¤ë©´, ê¼­ ë‘ íŒŒì¼ì„ ì§€ìš°ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”!** ì•ˆê·¸ëŸ¬ë©´ ê¸°ì¡´ íŒŒì¼ì´ load ë©ë‹ˆë‹¤.

2. ëª¨ë¸ì˜ ê²½ìš° `--overwrite_cache` ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ê°™ì€ í´ë”ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 

3. `./outputs/` í´ë” ë˜í•œ `--overwrite_output_dir` ì„ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ê°™ì€ í´ë”ì— ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
