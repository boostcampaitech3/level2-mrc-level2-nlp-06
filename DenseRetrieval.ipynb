{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 15:11:21.993710: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-10 15:11:21.993752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from datasets import DatasetDict, load_from_disk, load_metric\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.10.0+cu102].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwer\n",
    "class DenseRetrieval:\n",
    "    def __init__(self, args, dataset, num_neg, tokenizer, p_encoder, q_encoder):\n",
    "        self.args = args\n",
    "        self.dataset = dataset\n",
    "        self.num_neg = num_neg\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.p_encoder = p_encoder\n",
    "        self.q_encoder = q_encoder\n",
    "\n",
    "        self.prepare_in_batch_negative(num_neg=num_neg)\n",
    "\n",
    "    def prepare_in_batch_negative(self, dataset=None, num_neg=2, tokenizer=None):\n",
    "        if dataset is None:\n",
    "            dataset = self.dataset\n",
    "\n",
    "        if tokenizer is None:\n",
    "            tokenizer = self.tokenizer\n",
    "\n",
    "        # 1. In-Batch-Negative 만들기\n",
    "        # CORPUS를 np.array로 변환해줍니다.        \n",
    "        corpus = np.array(list(set([example for example in dataset['context']])))\n",
    "        p_with_neg = []\n",
    "\n",
    "        for c in dataset['context']:\n",
    "            \n",
    "            while True:\n",
    "                neg_idxs = np.random.randint(len(corpus), size=num_neg)\n",
    "\n",
    "                if not c in corpus[neg_idxs]:\n",
    "                    p_neg = corpus[neg_idxs]\n",
    "\n",
    "                    p_with_neg.append(c)\n",
    "                    p_with_neg.extend(p_neg)\n",
    "                    break\n",
    "\n",
    "        # 2. (Question, Passage) 데이터셋 만들어주기\n",
    "        q_seqs = tokenizer(dataset['question'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        p_seqs = tokenizer(p_with_neg, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "\n",
    "        max_len = p_seqs['input_ids'].size(-1)\n",
    "        p_seqs['input_ids'] = p_seqs['input_ids'].view(-1, num_neg+1, max_len)\n",
    "        p_seqs['attention_mask'] = p_seqs['attention_mask'].view(-1, num_neg+1, max_len)\n",
    "        p_seqs['token_type_ids'] = p_seqs['token_type_ids'].view(-1, num_neg+1, max_len)\n",
    "\n",
    "        train_dataset = TensorDataset(\n",
    "            p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'], \n",
    "            q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids']\n",
    "        )\n",
    "\n",
    "        self.train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=self.args.per_device_train_batch_size)\n",
    "\n",
    "        valid_seqs = tokenizer(dataset['context'], padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        passage_dataset = TensorDataset(\n",
    "            valid_seqs['input_ids'], valid_seqs['attention_mask'], valid_seqs['token_type_ids']\n",
    "        )\n",
    "        self.passage_dataloader = DataLoader(passage_dataset, batch_size=self.args.per_device_train_batch_size)\n",
    "\n",
    "\n",
    "    def train(self, args=None):\n",
    "\n",
    "        if args is None:\n",
    "            args = self.args\n",
    "        batch_size = args.per_device_train_batch_size\n",
    "\n",
    "        # Optimizer\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "            {'params': [p for n, p in self.p_encoder.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in self.q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args.weight_decay},\n",
    "            {'params': [p for n, p in self.q_encoder.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "        t_total = len(self.train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "\n",
    "        # Start training!\n",
    "        global_step = 0\n",
    "\n",
    "        self.p_encoder.zero_grad()\n",
    "        self.q_encoder.zero_grad()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        train_iterator = tqdm(range(int(args.num_train_epochs)), desc=\"Epoch\")\n",
    "        # for _ in range(int(args.num_train_epochs)):\n",
    "        for _ in train_iterator:\n",
    "\n",
    "            with tqdm(self.train_dataloader, unit=\"batch\") as tepoch:\n",
    "                for batch in tepoch:\n",
    "\n",
    "                    p_encoder.train()\n",
    "                    q_encoder.train()\n",
    "            \n",
    "                    targets = torch.zeros(batch_size).long() # positive example은 전부 첫 번째에 위치하므로\n",
    "                    targets = targets.to(args.device)\n",
    "\n",
    "                    p_inputs = {\n",
    "                        'input_ids': batch[0].view(batch_size * (self.num_neg + 1), -1).to(args.device),\n",
    "                        'attention_mask': batch[1].view(batch_size * (self.num_neg + 1), -1).to(args.device),\n",
    "                        'token_type_ids': batch[2].view(batch_size * (self.num_neg + 1), -1).to(args.device)\n",
    "                    }\n",
    "            \n",
    "                    q_inputs = {\n",
    "                        'input_ids': batch[3].to(args.device),\n",
    "                        'attention_mask': batch[4].to(args.device),\n",
    "                        'token_type_ids': batch[5].to(args.device)\n",
    "                    }\n",
    "            \n",
    "                    p_outputs = self.p_encoder(**p_inputs)  # (batch_size*(num_neg+1), emb_dim)\n",
    "                    q_outputs = self.q_encoder(**q_inputs)  # (batch_size*, emb_dim)\n",
    "\n",
    "                    # Calculate similarity score & loss\n",
    "                    p_outputs = p_outputs.view(batch_size, self.num_neg + 1, -1)\n",
    "                    q_outputs = q_outputs.view(batch_size, 1, -1)\n",
    "\n",
    "                    sim_scores = torch.bmm(q_outputs, torch.transpose(p_outputs, 1, 2)).squeeze()  #(batch_size, num_neg + 1)\n",
    "                    sim_scores = sim_scores.view(batch_size, -1)\n",
    "                    sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "\n",
    "                    loss = F.nll_loss(sim_scores, targets)\n",
    "                    tepoch.set_postfix(loss=f'{str(loss.item())}')\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "\n",
    "                    self.p_encoder.zero_grad()\n",
    "                    self.q_encoder.zero_grad()\n",
    "\n",
    "                    global_step += 1\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    del p_inputs, q_inputs\n",
    "\n",
    "\n",
    "    def get_relevant_doc(self, query, k=1, args=None, p_encoder=None, q_encoder=None):\n",
    "        if args is None:\n",
    "            args = self.args\n",
    "\n",
    "        if p_encoder is None:\n",
    "            p_encoder = self.p_encoder\n",
    "\n",
    "        if q_encoder is None:\n",
    "            q_encoder = self.q_encoder\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p_encoder.eval()\n",
    "            q_encoder.eval()\n",
    "\n",
    "            q_seqs_val = self.tokenizer([query], padding=\"max_length\", truncation=True, return_tensors='pt').to(args.device)\n",
    "            q_emb = q_encoder(**q_seqs_val).to('cpu')  # (num_query=1, emb_dim)\n",
    "\n",
    "            p_embs = []\n",
    "            for batch in self.passage_dataloader:\n",
    "\n",
    "                batch = tuple(t.to(args.device) for t in batch)\n",
    "                p_inputs = {\n",
    "                    'input_ids': batch[0],\n",
    "                    'attention_mask': batch[1],\n",
    "                    'token_type_ids': batch[2]\n",
    "                }\n",
    "                p_emb = p_encoder(**p_inputs).to('cpu')\n",
    "                p_embs.append(p_emb)\n",
    "\n",
    "        p_embs = torch.stack(p_embs, dim=0).view(len(self.passage_dataloader.dataset), -1)  # (num_passage, emb_dim)\n",
    "\n",
    "        dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
    "        rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
    "        return rank[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "      \n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "  \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋과 모델은 아래와 같이 불러옵니다.\n",
    "train_dataset = load_from_disk(\"../data/train_dataset\")['train']\n",
    "\n",
    "# 메모리가 부족한 경우 일부만 사용하세요 !\n",
    "num_sample = 1500\n",
    "sample_idx = np.random.choice(range(len(train_dataset)), num_sample)\n",
    "train_dataset = train_dataset[sample_idx]\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "model_checkpoint = 'klue/bert-base'\n",
    "\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = DenseRetrieval(\n",
    "    args=args,\n",
    "    dataset=train_dataset,\n",
    "    num_neg=4,\n",
    "    tokenizer=tokenizer,\n",
    "    p_encoder=p_encoder,\n",
    "    q_encoder=q_encoder,\n",
    ")\n",
    "# retriever.train() \n",
    "\n",
    "query = '강희제가 1717년에 쓴 글은 누구를 위해 쓰여졌는가?'\n",
    "results = retriever.get_relevant_doc(query=query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search Query] 강희제가 1717년에 쓴 글은 누구를 위해 쓰여졌는가?\n",
      "\n",
      "Top-1th Passage (Index 791)\n",
      "('1960년 8월 19일 국회에서 장면의 총리 지명 동의안 표결이 있기 직전, 김두한이 장면의 친일경력을 문제삼기도 했다. 김두한은 '\n",
      " '장면에게 역사적인 귀한 표를 던져서는 안 된다는 내용과 장면의 창씨명을 적은 전단을 뿌리고, 만일 장면을 총리로 뽑는다면 여의도 의사당을 '\n",
      " '불살라 버리겠다고 외쳤다. \\\\n\\\\n한편 김수환은 그가 조선총독부로부터 학생들을 구하기 위해 오버한 것이라고 밝히기도 했다. 김 '\n",
      " '추기경이 졸업반인 5학년 때의 일화가 전해진다. 일제에 대한 울분을 참지 못했던 학생 김수환은 ‘수신(修身) 시간’에 ‘황국신민으로서 '\n",
      " '소감을 쓰라’는 시험문제를 받았다. “황국신민이 아니어서 소감이 없다.”라고 답했다고 밝히고 있다. ”\\\\n\\\\n김수환에 의하면 장면의 '\n",
      " \"배려로 오히려 무사했다 한다. '결국 교장이던 장 전 총리에게 불려가 뺨을 맞았다. 장 전 총리가 김수환 학생을 호출해 일부러 꾸짖은 \"\n",
      " '것은 ‘이대로 가다가는 큰 재목 하나를 잃겠다’는 생각 때문이었다. 수신 담당 선생에게 선처를 부탁하기 위해서도 절차가 필요하기도 '\n",
      " '했다.건국 60년 특별연재/책으로 본 한국 현대인물사-마지막회 김수환 추기경]</ref>')\n",
      "Top-2th Passage (Index 2850)\n",
      "('공민왕에게 후원받은 신돈이 일련의 개혁정책으로써 영향력을 확대하자 권문세족들의 반발은 극심했다 그 결과 오인택(吳仁澤), '\n",
      " '조희고(趙希古), 김원명(金元命)을 위시해 많은 공신이 유배되었고 그 사람들의 가족은 노비로 편입되었다\\\\n\\\\n기득권 세력을 견제하려는 '\n",
      " '사람에 관한 쇄신은 신돈이 집권한 지 30일 만에 친훈(親勳)과 명망 있는 사람을 파면시켜 내쫓으면서 시작되었다. 이때 재상과 '\n",
      " '대간(臺諫)이 모두 신돈의 입에서 나왔다는 기록은 이런 사정을 웅변한다. 신돈은 관리를 승진시킬 때 근무연한을 고려하는 '\n",
      " '순자격식(循資格式)을 실시하기도 하였는데 이것은 권세가의 자제들이 남보다 빨리 승진하는 폐단을 막으려는 시도였다. 그리고 신돈은 '\n",
      " '현량(賢良)의 등용을 강조하면서 개혁 세력을 양성하려고 애썼다. 신돈이 전선(銓選)하면서 현량을 천거한다고 자칭하였으나 제목(除目)이 '\n",
      " '발표되고 보니 천거된 사람들이 모두 평소에 신돈이 마음에 둔 사람이었다는 기록이 이런 사실을 보여준다 신돈이 천거한 현량은 대부분 유교 '\n",
      " '소양을 갖춘 인재들이었다')\n",
      "Top-3th Passage (Index 1724)\n",
      "('공민왕에게 후원받은 신돈이 일련의 개혁정책으로써 영향력을 확대하자 권문세족들의 반발은 극심했다 그 결과 오인택(吳仁澤), '\n",
      " '조희고(趙希古), 김원명(金元命)을 위시해 많은 공신이 유배되었고 그 사람들의 가족은 노비로 편입되었다\\\\n\\\\n기득권 세력을 견제하려는 '\n",
      " '사람에 관한 쇄신은 신돈이 집권한 지 30일 만에 친훈(親勳)과 명망 있는 사람을 파면시켜 내쫓으면서 시작되었다. 이때 재상과 '\n",
      " '대간(臺諫)이 모두 신돈의 입에서 나왔다는 기록은 이런 사정을 웅변한다. 신돈은 관리를 승진시킬 때 근무연한을 고려하는 '\n",
      " '순자격식(循資格式)을 실시하기도 하였는데 이것은 권세가의 자제들이 남보다 빨리 승진하는 폐단을 막으려는 시도였다. 그리고 신돈은 '\n",
      " '현량(賢良)의 등용을 강조하면서 개혁 세력을 양성하려고 애썼다. 신돈이 전선(銓選)하면서 현량을 천거한다고 자칭하였으나 제목(除目)이 '\n",
      " '발표되고 보니 천거된 사람들이 모두 평소에 신돈이 마음에 둔 사람이었다는 기록이 이런 사실을 보여준다 신돈이 천거한 현량은 대부분 유교 '\n",
      " '소양을 갖춘 인재들이었다')\n",
      "Top-4th Passage (Index 2799)\n",
      "('마라의 모습은 이상화되어 있다. 예를 들면, 그림에는 마라의 피부에 생긴 어떤 문제도 포함하고 있지 않으며, 마라의 피부는 깨끗하고 '\n",
      " '흠결이 없다. 그러나 다비드는 초록색 카페트, 종이, 펜 등의 다른 세부 사항은 그렸다. 다비드는 그의 국민공회 동료에게 살해된 친구가 '\n",
      " '\"écrivant pour le bonheur du peuple\"(사람들의 행복을 위한 글을 쓰는 것)으로 묘사하겠다고 약속하였다. '\n",
      " '《마라의 죽음》은 매력적인 영웅을 추모하기 위하여 제작되었다. 마라의 왼손에 쥐어진 종이에서 샤를로트 코르데라는 이름이 보이지만 정작 '\n",
      " '그녀 자신은 보이지 않는다. 면밀한 조사에 의하면 이 그림은 코르데와 다른 사람이 아직 마라 곁에 있을 때의 마라의 마지막 모습을 '\n",
      " '묘사한다. (코르데는 탈출하려 하지 않았다.) 다비드는 순교자의 고통 그 이상을 묘사하려고 하였다 .\\\\n\\\\n다비드는 군주제와 카톨릭 '\n",
      " '교회와 오랫동안 결부된 신성한 성질을 새로운 프랑스 혁명으로 이전시키려고 하였다. 그는 기독교의 순교자를 연상시키는 스타일로, 부드럽고 '\n",
      " '선명한 빛으로 둘러싸인 혁명의 순교자인 마라를 그렸다')\n",
      "Top-5th Passage (Index 1095)\n",
      "('사신천지서라는 고대 소설책을 통해 다른 차원의 세계로 가게 된다는 설정은 이세계(異世界) 소환 만화에서 흔히 볼 수 있는 설정이지만 '\n",
      " '여기에 주작, 청룡, 현무, 백호와 같은 동양의 도가사상에 기반한 4개 세력과 함께, 각각의 세력이 7명의 전사를 모아 각자를 상징하는 '\n",
      " '성물을 소환하면 소원을 이룰 수 있다는 이야기가 가미됨으로써 이야기가 흥미진진하게 진행된다.\\\\n게다가 현실세계에서 절친한 친구가 각 '\n",
      " '세력의 무녀가 되어 대치하는 구도로 진행되고, 각 전사들과의 이루어질 수 없는 사랑이야기가 들어가면서 이 작품은 한층 더 탄탄한 '\n",
      " '긴장·갈등관계를 이루며 치밀하게 진행된다.\\\\n\\\\n관련 팬시 상품들로도 유명한 작품이며, 특히 일본 순정만화 중 영문권 국가들에서도 '\n",
      " '폭발적인 인기를 끈 것으로도 주목을 받았다.\\\\n\\\\n환상게임 애니메이션으로는 TV 시리즈를 비롯해 1기~3기까지 13편의 OVA가 '\n",
      " '있으며, TV 시리즈의 경우, 총 52화로 1995년 4월 6일부터 1996년 3월 28일까지 테레비 도쿄를 통해 방영되었다. '\n",
      " '투니버스에서는 52화 전편 방송되었다. 1997년 6월 투니버스에서 방영되었었는데 당시엔 케이블도 지상파와 마찬가지로 왜색이 짙은 부분을 '\n",
      " '편집하는 성향이 있었으므로 왜색이 있는 일부분을 편집해야 했다. (홍콩 ATV는 등급을 전체 관람가로 맞추기 위해 선정성이 전체 관람가에 '\n",
      " '맞추기 부적절한 장면들을 편집)')\n"
     ]
    }
   ],
   "source": [
    "print(f\"[Search Query] {query}\\n\")\n",
    "\n",
    "indices = results.tolist()\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"Top-{i + 1}th Passage (Index {idx})\")\n",
    "    pprint(retriever.dataset['context'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
