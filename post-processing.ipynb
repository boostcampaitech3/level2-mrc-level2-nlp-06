{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 16:02:27.042327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-09 16:02:27.042370: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments, EvalPrediction, default_data_collator, DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "from utils_qa import postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.10.0+cu102].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_kor_v1 (/opt/ml/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 및 평가지표 불러오기\n",
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(\"squad_kor_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained 모델 불러오기\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "model_name = \"klue/bert-base\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_name\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    use_fast=True\n",
    ")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_name,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "\n",
    "# 데이터 전처리를 위한 파라미터\n",
    "max_seq_length = 384 # 질문과 컨텍스트, special token을 합한 문자열의 최대 길이\n",
    "pad_to_max_length = True\n",
    "doc_stride = 128 # 컨텍스트가 너무 길어서 나눴을 때 오버랩되는 시퀀스 길이\n",
    "\n",
    "# 학습을 위한 파라미터 (파라미터는 편하게 수정해서 사용하시면 됩니다) \n",
    "max_train_samples = 16\n",
    "max_val_samples = 16\n",
    "preprocessing_num_workers = 4\n",
    "batch_size = 16\n",
    "num_train_epochs = 30\n",
    "n_best_size = 20\n",
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train을 위한 데이터 준비\n",
    "def prepare_train_features(examples):\n",
    "    # 주어진 텍스트를 토크나이징함\n",
    "    # 이 때 텍스트의 길이가 max_seq_length를 넘으면 stride만큼 슬라이딩하며 여러 개로 나눔\n",
    "    # 즉, 하나의 example에서 일부분이 겹치는 여러 sequence(feature)가 생길 수 있음\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",  # max_seq_length까지 truncate함 / pair의 두번째 파트(context)만 잘라냄\n",
    "        max_length=max_seq_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True, # 길이를 넘어가는 토큰들을 반환할 것인지\n",
    "        return_offsets_mapping=True,  # 각 토큰에 대해 (char_start, char_end) 정보를 반환한 것인지\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    # example 하나가 여러 sequence에 대응하는 경우를 위해 매핑이 필요\n",
    "    overflow_to_sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\") # [0 ,0, 1, 1,]\n",
    "    # offset_mappings으로 토큰이 원본 context 내 몇번째 글자부터 몇번째 글자까지 해당하는지 알 수 있음\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\") # [(0, 0) , (0, 1) .... ]\n",
    "\n",
    "    # 정답지를 만들기 위한 리스트\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        \n",
    "        # 해당 example에 해당하는 sequence를 찾음\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "         \n",
    "        # sequence가 속하는 example을 찾는다\n",
    "        example_index = overflow_to_sample_mapping[i]\n",
    "        answers = examples[\"answers\"][example_index]\n",
    "        \n",
    "        # 텍스트에서 answer의 시작점, 끝점\n",
    "        answer_start_offset = answers[\"answer_start\"][0]\n",
    "        answer_end_offset = answer_start_offset + len(answers[\"text\"][0])\n",
    "        \n",
    "        # 텍스트에서 현재 span의 시작 토큰 인덱스\n",
    "        token_start_index = 0\n",
    "        while sequence_ids[token_start_index] != 1:\n",
    "            token_start_index += 1\n",
    "        \n",
    "        # 텍스트에서 현재 span 끝 토큰 인덱스\n",
    "        token_end_index = len(input_ids) - 1\n",
    "        while sequence_ids[token_end_index] != 1:\n",
    "            token_end_index -= 1\n",
    "        \n",
    "        \n",
    "        # answer가 현재 span을 벗어났는지 체크\n",
    "        if not (\n",
    "            offsets[token_start_index][0] <= answer_start_offset\n",
    "            and offsets[token_end_index][1] >= answer_end_offset\n",
    "        ):\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # token_start_index와 token_end_index를 answer의 시작점과 끝점으로 옮김\n",
    "            while (\n",
    "                token_start_index < len(offsets)\n",
    "                and offsets[token_start_index][0] <= answer_start_offset\n",
    "            ):\n",
    "                token_start_index += 1\n",
    "            tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "            while offsets[token_end_index][1] >= answer_end_offset:\n",
    "                token_end_index -= 1\n",
    "            tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e8410ce9944e9ca1efc5dca28e8478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=1.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98362a8b96247c3b14e1c6f04045f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=1.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55de39364e647ae8d3f222e271ac9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=1.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2f19819a8c4958b001f79605ba7293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=1.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 전체 train dataset을 사용하는 예제가 아니고, sampling된 데이터를 사용하는 코드입니다. 적절하게 코드를 수정하여 사용하셔도 좋습니다.\n",
    "train_dataset = train_dataset.select(range(max_train_samples)) \n",
    "column_names = datasets[\"train\"].column_names\n",
    "train_dataset = train_dataset.map(\n",
    "        prepare_train_features,\n",
    "        batched=True,\n",
    "        num_proc=preprocessing_num_workers,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation을 위한 데이터 준비\n",
    "def prepare_validation_features(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples['question'],\n",
    "        examples['context'],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1\n",
    "\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fdbb08161443598cf85219f2893233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=2.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c4f35a65aa4471ba1ae003026ede18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=2.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192297a7b1fb43cbab849ba949d74d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=2.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253c0c7544ef443ea51730cbcc0609d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=2.0, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터로 평가\n",
    "eval_examples = datasets[\"validation\"]\n",
    "\n",
    "# 샘플 데이터로 평가\n",
    "# eval_examples = eval_examples.select(range(max_val_samples)) \n",
    "\n",
    "eval_dataset = eval_examples.map(\n",
    "        prepare_validation_features,\n",
    "        batched=True,\n",
    "        num_proc=preprocessing_num_workers,\n",
    "        remove_columns=column_names,\n",
    "        load_from_cache_file=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def post_processing_function(examples, features, predictions):\n",
    "#     # Post-processing: start logits과 end logits을 original context의 정답과 match시킵니다.\n",
    "#     predictions = postprocess_qa_predictions(\n",
    "#         examples=examples,\n",
    "#         features=features,\n",
    "#         predictions=predictions,\n",
    "#         max_answer_length=max_answer_length, # 30\n",
    "#         output_dir='./rudals/outputs/', # temporal\n",
    "#     )\n",
    "    \n",
    "#     # Metric을 구할 수 있도록 Format을 맞춰줍니다.\n",
    "#     formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in predictions.items()]\n",
    "#     references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
    "#     return EvalPrediction(predictions=formatted_predictions, label_ids=references)# 모델 예측 값을 후처리 하는 함수 (qa 성능 향상에 필수적임)\n",
    "\n",
    "def post_processing_function(examples, features, predictions):\n",
    "    # Post-processing: original context에서 start logit과 end logit을 matching\n",
    "    predictions = postprocess_qa_predictions(\n",
    "        examples=examples,\n",
    "        features=features,\n",
    "        predictions=predictions,\n",
    "        version_2_with_negative=False,\n",
    "        n_best_size=n_best_size,\n",
    "        max_answer_length=max_answer_length,\n",
    "        null_score_diff_threshold=0.0,\n",
    "        output_dir=training_args.output_dir,\n",
    "        is_world_process_zero=trainer.is_world_process_zero(),\n",
    "    )\n",
    "    \n",
    "    # Metric을 계산할 수 있는 format으로 수정\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in predictions.items()]\n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]]\n",
    "    return EvalPrediction(predictions=formatted_predictions, label_ids=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 Arguments 정의\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs\",\n",
    "    do_train=True, \n",
    "    do_eval=True, \n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    eval_examples=datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    post_process_function=post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/code/post-processing.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.160.107/opt/ml/input/code/post-processing.ipynb#ch0000022vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwandb\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.160.107/opt/ml/input/code/post-processing.ipynb#ch0000022vscode-remote?line=1'>2</a>\u001b[0m wandb\u001b[39m.\u001b[39;49mlogin()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.160.107/opt/ml/input/code/post-processing.ipynb#ch0000022vscode-remote?line=2'>3</a>\u001b[0m wandb\u001b[39m.\u001b[39minit(project\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMRC\u001b[39m\u001b[39m'\u001b[39m, entity\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mboostcamp_nlp06\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTEST\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py:73\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(anonymous, key, relogin, host, force, timeout)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=50'>51</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=51'>52</a>\u001b[0m \u001b[39mLog in to W&B.\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=52'>53</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=68'>69</a>\u001b[0m \u001b[39m    UsageError - if api_key can not configured and no tty\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=69'>70</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=71'>72</a>\u001b[0m _handle_host_wandb_setting(host)\n\u001b[0;32m---> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=72'>73</a>\u001b[0m \u001b[39mif\u001b[39;00m wandb\u001b[39m.\u001b[39;49msetup()\u001b[39m.\u001b[39m_settings\u001b[39m.\u001b[39m_noop:\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=73'>74</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_login.py?line=74'>75</a>\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlocals\u001b[39m())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:318\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=316'>317</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(settings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39m\"\u001b[39m\u001b[39m_WandbSetup\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=317'>318</a>\u001b[0m     ret \u001b[39m=\u001b[39m _setup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=318'>319</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:313\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(settings, _reset)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=310'>311</a>\u001b[0m     _WandbSetup\u001b[39m.\u001b[39m_instance \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=311'>312</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=312'>313</a>\u001b[0m wl \u001b[39m=\u001b[39m _WandbSetup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=313'>314</a>\u001b[0m \u001b[39mreturn\u001b[39;00m wl\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:299\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=296'>297</a>\u001b[0m     _WandbSetup\u001b[39m.\u001b[39m_instance\u001b[39m.\u001b[39m_update(settings\u001b[39m=\u001b[39msettings)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=297'>298</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=298'>299</a>\u001b[0m _WandbSetup\u001b[39m.\u001b[39m_instance \u001b[39m=\u001b[39m _WandbSetup__WandbSetup(settings\u001b[39m=\u001b[39;49msettings, pid\u001b[39m=\u001b[39;49mpid)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:107\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup.__init__\u001b[0;34m(self, settings, environ, pid)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=103'>104</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_early_logger \u001b[39m=\u001b[39m _EarlyLogger()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=104'>105</a>\u001b[0m _set_logger(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_early_logger)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=106'>107</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings_setup(settings, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_early_logger)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=107'>108</a>\u001b[0m \u001b[39m# self._settings.freeze()\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=109'>110</a>\u001b[0m wandb\u001b[39m.\u001b[39mtermsetup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings, logger)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:134\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._settings_setup\u001b[0;34m(self, settings, early_logger)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=129'>130</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(settings, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=130'>131</a>\u001b[0m     \u001b[39m# if passed settings arg is a mapping, update the settings with it\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=131'>132</a>\u001b[0m     s\u001b[39m.\u001b[39m_apply_setup(settings, _logger\u001b[39m=\u001b[39mearly_logger)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=133'>134</a>\u001b[0m s\u001b[39m.\u001b[39;49m_infer_settings_from_environment()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=134'>135</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s\u001b[39m.\u001b[39m_cli_only_mode:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=135'>136</a>\u001b[0m     s\u001b[39m.\u001b[39m_infer_run_settings_from_environment(_logger\u001b[39m=\u001b[39mearly_logger)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py:1325\u001b[0m, in \u001b[0;36mSettings._infer_settings_from_environment\u001b[0;34m(self, _logger)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1318'>1319</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_code \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_code \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1319'>1320</a>\u001b[0m     os\u001b[39m.\u001b[39mgetenv(wandb\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mSAVE_CODE) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1320'>1321</a>\u001b[0m     \u001b[39mor\u001b[39;00m os\u001b[39m.\u001b[39mgetenv(wandb\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mDISABLE_CODE) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1321'>1322</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1322'>1323</a>\u001b[0m     settings[\u001b[39m\"\u001b[39m\u001b[39msave_code\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mshould_save_code()\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1324'>1325</a>\u001b[0m settings[\u001b[39m\"\u001b[39m\u001b[39mdisable_git\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mdisable_git()\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1326'>1327</a>\u001b[0m \u001b[39m# Attempt to get notebook information if not already set by the user\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1327'>1328</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotebook_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotebook_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/env.py:349\u001b[0m, in \u001b[0;36mdisable_git\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=346'>347</a>\u001b[0m \u001b[39mif\u001b[39;00m env \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=347'>348</a>\u001b[0m     env \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=348'>349</a>\u001b[0m val \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mget(DISABLE_GIT, default\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=349'>350</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(val) \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=350'>351</a>\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m val\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfalse\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: get() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project='MRC', entity='boostcamp_nlp06', name='TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 996, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 133, in setup\n",
      "    self._wl = wandb_setup.setup()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 318, in setup\n",
      "    ret = _setup(settings=settings)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 313, in _setup\n",
      "    wl = _WandbSetup(settings=settings)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 299, in __init__\n",
      "    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 107, in __init__\n",
      "    self._settings = self._settings_setup(settings, self._early_logger)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 134, in _settings_setup\n",
      "    s._infer_settings_from_environment()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py\", line 1325, in _infer_settings_from_environment\n",
      "    settings[\"disable_git\"] = wandb.env.disable_git()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/wandb/env.py\", line 349, in disable_git\n",
      "    val = env.get(DISABLE_GIT, default=False)\n",
      "TypeError: get() takes no keyword arguments\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:996\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=994'>995</a>\u001b[0m wi \u001b[39m=\u001b[39m _WandbInit()\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=995'>996</a>\u001b[0m wi\u001b[39m.\u001b[39;49msetup(kwargs)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=996'>997</a>\u001b[0m except_exit \u001b[39m=\u001b[39m wi\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39m_except_exit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:133\u001b[0m, in \u001b[0;36m_WandbInit.setup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=130'>131</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprinter\u001b[39m.\u001b[39mdisplay(line, status\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=132'>133</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wl \u001b[39m=\u001b[39m wandb_setup\u001b[39m.\u001b[39;49msetup()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=133'>134</a>\u001b[0m \u001b[39m# Make sure we have a logger setup (might be an early logger)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:318\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=316'>317</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(settings\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39m\"\u001b[39m\u001b[39m_WandbSetup\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=317'>318</a>\u001b[0m     ret \u001b[39m=\u001b[39m _setup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=318'>319</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:313\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(settings, _reset)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=311'>312</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=312'>313</a>\u001b[0m wl \u001b[39m=\u001b[39m _WandbSetup(settings\u001b[39m=\u001b[39;49msettings)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=313'>314</a>\u001b[0m \u001b[39mreturn\u001b[39;00m wl\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:299\u001b[0m, in \u001b[0;36m_WandbSetup.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=297'>298</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=298'>299</a>\u001b[0m _WandbSetup\u001b[39m.\u001b[39m_instance \u001b[39m=\u001b[39m _WandbSetup__WandbSetup(settings\u001b[39m=\u001b[39;49msettings, pid\u001b[39m=\u001b[39;49mpid)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:107\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup.__init__\u001b[0;34m(self, settings, environ, pid)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=104'>105</a>\u001b[0m _set_logger(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_early_logger)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=106'>107</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_settings_setup(settings, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_early_logger)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=107'>108</a>\u001b[0m \u001b[39m# self._settings.freeze()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py:134\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._settings_setup\u001b[0;34m(self, settings, early_logger)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=131'>132</a>\u001b[0m     s\u001b[39m.\u001b[39m_apply_setup(settings, _logger\u001b[39m=\u001b[39mearly_logger)\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=133'>134</a>\u001b[0m s\u001b[39m.\u001b[39;49m_infer_settings_from_environment()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py?line=134'>135</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s\u001b[39m.\u001b[39m_cli_only_mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py:1325\u001b[0m, in \u001b[0;36mSettings._infer_settings_from_environment\u001b[0;34m(self, _logger)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1322'>1323</a>\u001b[0m     settings[\u001b[39m\"\u001b[39m\u001b[39msave_code\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mshould_save_code()\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1324'>1325</a>\u001b[0m settings[\u001b[39m\"\u001b[39m\u001b[39mdisable_git\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mdisable_git()\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_settings.py?line=1326'>1327</a>\u001b[0m \u001b[39m# Attempt to get notebook information if not already set by the user\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/env.py:349\u001b[0m, in \u001b[0;36mdisable_git\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=347'>348</a>\u001b[0m     env \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=348'>349</a>\u001b[0m val \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mget(DISABLE_GIT, default\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/env.py?line=349'>350</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(val) \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: get() takes no keyword arguments",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/code/post-processing.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.160.107/opt/ml/input/code/post-processing.ipynb#ch0000020vscode-remote?line=0'>1</a>\u001b[0m train_result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1069\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer.py?line=1065'>1066</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_flos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtotal_flos\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer.py?line=1066'>1067</a>\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer.py?line=1068'>1069</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallback_handler\u001b[39m.\u001b[39;49mon_train_begin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontrol)\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer.py?line=1070'>1071</a>\u001b[0m \u001b[39m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer.py?line=1071'>1072</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mignore_data_skip:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py:340\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=337'>338</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_begin\u001b[39m(\u001b[39mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=338'>339</a>\u001b[0m     control\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=339'>340</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_event(\u001b[39m\"\u001b[39;49m\u001b[39mon_train_begin\u001b[39;49m\u001b[39m\"\u001b[39;49m, args, state, control)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py:378\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=375'>376</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_event\u001b[39m(\u001b[39mself\u001b[39m, event, args, state, control, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=376'>377</a>\u001b[0m     \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=377'>378</a>\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(callback, event)(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=378'>379</a>\u001b[0m             args,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=379'>380</a>\u001b[0m             state,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=380'>381</a>\u001b[0m             control,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=381'>382</a>\u001b[0m             model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=382'>383</a>\u001b[0m             tokenizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=383'>384</a>\u001b[0m             optimizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=384'>385</a>\u001b[0m             lr_scheduler\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_scheduler,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=385'>386</a>\u001b[0m             train_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=386'>387</a>\u001b[0m             eval_dataloader\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_dataloader,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=387'>388</a>\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=388'>389</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=389'>390</a>\u001b[0m         \u001b[39m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/trainer_callback.py?line=390'>391</a>\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/integrations.py:629\u001b[0m, in \u001b[0;36mWandbCallback.on_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=626'>627</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wandb\u001b[39m.\u001b[39mfinish()\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=627'>628</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialized:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=628'>629</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup(args, state, model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/integrations.py:603\u001b[0m, in \u001b[0;36mWandbCallback.setup\u001b[0;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=599'>600</a>\u001b[0m     run_name \u001b[39m=\u001b[39m args\u001b[39m.\u001b[39mrun_name\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=601'>602</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wandb\u001b[39m.\u001b[39mrun \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=602'>603</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wandb\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=603'>604</a>\u001b[0m         project\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mWANDB_PROJECT\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mhuggingface\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=604'>605</a>\u001b[0m         name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=605'>606</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_args,\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=606'>607</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=607'>608</a>\u001b[0m \u001b[39m# add config parameters (run may have been created manually)\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/conda/lib/python3.8/site-packages/transformers/integrations.py?line=608'>609</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wandb\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mupdate(combined_dict, allow_val_change\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:1037\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=1034'>1035</a>\u001b[0m         \u001b[39mif\u001b[39;00m except_exit:\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=1035'>1036</a>\u001b[0m             os\u001b[39m.\u001b[39m_exit(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=1036'>1037</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mproblem\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merror_seen\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py?line=1037'>1038</a>\u001b[0m \u001b[39mreturn\u001b[39;00m run\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
